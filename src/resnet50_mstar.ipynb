{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=ToTensor()):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['BMP2', 'BTR70', 'T72']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(self.root_dir, class_name+'/')\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith('.jpg'):  \n",
    "                    self.images.append(os.path.join(class_dir, filename))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.images[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = 'C:/Users/tnblt/Desktop/project/data/converted_data_set/'\n",
    "train_dataset = CustomDataset(root_dir= os.path.join(project_path, 'TRAIN/17_DEG/'))\n",
    "test_dataset = CustomDataset(root_dir= os.path.join(project_path, 'TEST/15_DEG/'))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "\n",
    "model = models.resnet50(weights = ResNet50_Weights.DEFAULT)\n",
    "# mstar图片儿是灰度图，修改第一层的输入通道数\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "num_classes = 3\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# GPU\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:53<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 早停初始化\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "patience = 10  # 没有改善的训练次数\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 100  \n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(f\"loss: {loss.item()}\")\n",
    "        \n",
    "        # 如果验证损失有改善\n",
    "        if loss <= best_loss:\n",
    "            best_loss = loss\n",
    "            counter = 0\n",
    "        else: # 如果验证损失没有改善\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                #print(\"Early stopping, \", end=\"\")\n",
    "                break\n",
    "\n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 复位\n",
    "    best_loss = float('inf')\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 97.28937728937728\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        batch_correct = (predicted == labels).sum().item()\n",
    "        batch_total = labels.size(0)\n",
    "        correct += batch_correct\n",
    "        total += batch_total\n",
    "        #print(f'Batch Accuracy: {100 * batch_correct / batch_total}')\n",
    "        \n",
    "    print(f'Total Accuracy: {100 * correct / total}')    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
